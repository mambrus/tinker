\part{Writing TinKer - the sleepy kernel}
\chapter{Introduction}
A kernal can be written in numerous ways. TinKers does not in any way claim that this the only way, neighter the correct way to do it. Only that this is one way of doing it, based on a sertain set of philosofies, ambitions and ideas. One of them those ambitions is to make the kernel as readable and comprehensive as possible.

One of the original intentions with TinKer from the very start, was to write a kernel that would exeplyfy a text about kernels (this text actually). Therefore you will hopefully find that TinKer is written in such a way that you will be able to follow the code. Kernel theory is a quite difficult subject not normally tought to computer science novices. My ambition is also to make this knowledge available the freash mind of a student, on so that he'll be able to approach his upcomming carriear with a toolbox of knowledge. thereby making him able to select better solutions for his projects and to identify the really bad ones (most oftenly those based on FUD and who takes advantage of peoples uncertanty and ignorance),

You will notice that this text does not contain many references. This is intentional for two reasons. The first reason is tha most of the text here is based on my own isight and therefore there is no natural references. I.e. by doing this I'm also vounerable for that some of the conclusions are wrong- I'm delighted however to notice that many of the conclutions are verifiable, and should I detect something thats inaccurate I will naturally change those conclutions.  The second reason is a little more difficult to realize. This subject is very difficult. Most oftenly the difficulty lays in the fact that it's difficult to explain. It's like math, you need to come to "insights". The formulas and what-not are just notation (or language). One has to learn the notation to be able to come to insight\ldots.

When it comes to computer sience there are many notations and it spawns from computer languages, to grapghical descriptive languages and mathematical expression. For the advanced scientist, using any of these (based on the subject of course) this is naturally the best way. But for the novice, this becomes a theshold most oftenly very hard to overcome in a limited amount of time. Scientific work is normally written in such notation however.

\begin{table}[!hbp]
\begin{tabular}{|r|rl|}
\hline
CPU archetecture 	& Tool-chain 	& execution type\\ \hline
x86 			& $GNU_1$	& Linux \\
x86 			& $GNU_1$	& Cygwin/Win32 \\
x86 			& MSVC		& Win32 \\
x86 			& Borland	& Win32/DOS \\
ARM7			& $GNU_3$	& HW\\
ARM7			& $GNU_2$	& HW\\
Blackfin		& $GNU_2$	& HW\\
PowerPC 		& $GNU_2$	& HW\\
C166 			& Keil		& HW\\
8051 			& IAR 		& HW (old discont.)\\
Z80 			& IAR 		& HW (old discont.)\\ \hline
\end{tabular}

\caption{TinKer ports (Nov 2006)}\label{ports}
\end{table}

\marginpar{%
$GNU_1$ glibc\\ $GNU_2$ newlib / HIXS\\ $GNU_3$ newlib / def
}


%------------------------------------------------------------------------------
%------------------------------------------------------------------------------
%------------------------------------------------------------------------------

\chapter{Quick tour - writing a kernel in 30 minuts}
\section{Genesis}
\label{kernel30}
I assume that you have allready written at least one simple program. What is that whne you look upon it really? What \textit{defines} a program?

\begin{itemize}
\item A program is an entity that descripes or instructs another entity what to do.
\item Doing so by implying a certain set of rules
\end{itemize}

	\paragraph{Sequence}

		In a computer program this boils down to something very similar to a written piece of paper. This might sond very obvious, but when you think of it. to be able to make any sence of what is written, we have to imply a certain set of rules. Normally you'd expect interpretation to be \textbf{sequencial} - i.e. one thing has to come before another in a certain order. Another thing is to define this \textbf{order} of execution in terms of left to right, top to bottom e.t.a.
\\
		A computer program is acually very similar. It has a defined order (normally from top to bottom) and it is normall thought of as sequential flow of execution. Think of it as a puncard, with a lot of holes placed in certain places on a piece of carbon paper (this is actually more than an analogy, it happens to be a historical fact of the very early computer memories).
\\
		We'll keep this anology in mind for a while, even though it is not strictlly true in all aspects.
	\begin{figure}[!hbp]
	\begin{dotpic}
		node [
			shape=record,
			style=filled,
			fillcolor=yellow,
			fontname=Courier,
			nojustify="true",
			fontsize=10.0
		];

		edge [
			color="red",
			fontname=Courier,
			nojustify="true",
			fontsize=10.0
		];

		graph [
			rankdir = "TB",
			fontname=Courier,
			nojustify="true",
			fontsize=10.0
		];

		MAIN [ orientation=73.0, label="{\
			---- START ----         | \
			do something   | \
			<m1> jump if somewhere  | \
			<m2> jump if somewhere   | \
			<m3> do something   | \
			<m4> jump if somewhere   | \
			<m5> do something   | \
			<call_from> call something | \
			<ret_from_call> continue do something | \
			---- END ---- }"];

		PROC [ orientation=73.0, label="{\
			<pi>  ---- PROC START ---- | \
			do something   | \
			do something   | \
			do something   | \      
			<po>  ----PROC END ----}"];


		MAIN:call_from:e -> PROC:pi:e 
		PROC:po:w -> MAIN:ret_from_call:w [label=RET];
	\end{dotpic}
	\caption{Flow of execution.\label{execflow}}	
	\end{figure}

	In the graph above, we've exeplified the analogy but also introduced yet two more common properties in a computer program, that of \textbf{execution control} (jump, if, while, case e.t.a.) and that of \textbf{encapulation and reuse} (proc, function e.t.a.). These properties are not common in normal written languagem but there exists other notations. Musical notes are a good example.
\\
	The latter two properties are really not important for our reasoning, but what is iportant is the idea of of an execution sequence and it's order. The red arrows are attempting to lead you into this thinking. You should now feel confortable with the expression \textit{"thread of execution"} and an anology of the directed sequence or flow. \textit{"Thread of execution"} can sometimes be shortened with just the word \textit{"thread"}.

	\paragraph{thread}
	\label{genesis_thread}
		Once one has accepted the analogy of \textit{"trhead of execution"} one needs to add yet another fundamental property until we can call it a \textit{computer thread}.

		If \textit{"trhead of execution"} symbolized the whole thread of execution in a processor, a program thread is thought of a tiny part of this total thread. Now, it's important to realize that it is a part of that totallity, and hence shares that "big" threads inbound notion of sequence and order. It's really simple, just think of it as a sawing thread that you've cut in a couple of pieces.

		Notice how we're speaking of \textit{one} thread of execution. In a single core CPU there can only exist one thread of execution. I.e. if that CPU runs with a kernel or OS, all these executives are just seemingly paralell. Sometimes the word concurrent programing is used to point out this fact. Only multicore CPU's or distributed systems can have \textit{true} paralellism. Even though concurrency is  a more accurate term than parallel, in this text we'll use both of them interchangivbly.

		Speaking of which, what is the difference between a thread and a program anyway?
		Answer: there is none (it only apears that way).

		Assume that somewhere there exists four functions called  do\_1, do\_2, do\_3 and do\_4 as in the program in table~\ref{hc1}.

		\begin{table}[!hbp]
		\begin{verbatim}
		#include "dofuncs.h"
		#define FOREVER 1
		int main( int argc, char **argv)
		{ 
        		while( FOREVER )
        		{
		                do_1();
		                do_2();
		                do_3();
		                do_4();
		        }
		}
		\end{verbatim}
		\caption{Hard-core shedule.\label{hc1}}
		\end{table}

	You will have to take my word for it for now. But those function calls in the above example are very similar (almost identical as a matter of fact) to threads.
	\\\\
	Imagine circles in in the diagrams that follow (figure~\ref{simpl1} and figure~\ref{simpl2}) representing functions, the arrows representing calls \& returns and the adjenctient number as execution order.

	%\clearpage
	\begin{figure}[!hbp]
	\begin{dotpic}
		node [shape=circle,fontsize=10.0];
		edge [fontsize=10.0];
		graph [rankdir = "TB",fontsize=10.0];

		do_1
		do_2
		func	
		do_3
		do_4

		func -> do_1		[label="1"]
		do_1 -> func		[label="2"]
		func -> do_2		[label="3"]
		do_2 -> func		[label="4"]
		func -> do_3		[label="5"]
		do_3 -> func		[label="6"]
		func -> do_4		[label="7"]
		do_4 -> func		[label="8"]
	\end{dotpic}
	\caption{Call-diagram of simple program.\label{simpl1}}	
	\end{figure}
	\footnote{The  middle circle in figure~\ref{simpl1} is the loop in our program in table~\ref{hc1}}
	\begin{figure}[!hbp]
	\begin{dotpic}
		node [shape=circle,fontsize=10.0];
		edge [fontsize=10.0];
		graph [rankdir = "TB",fontsize=10.0];

		do_1
		do_2
		func	
		do_3
		do_4

		do_1 -> func		[label="1"]
		func -> do_2		[label="2"]
		do_2 -> func		[label="3"]
		func -> do_3		[label="4"]
		do_3 -> func		[label="5"]
		func -> do_4		[label="6"]
		do_4 -> func		[label="7"]
	\end{dotpic}
	\caption{Call-diagram of something else.\label{simpl2}}
	\end{figure}
		
	Now, what is the difference between the graph in figure~\ref{simpl1} and that of figure~\ref{simpl2}?.

	Nothing really. The only difference is that the bubble called do\_1 starts the whole sequence, and it calls the middle circle instead of the other way around. \textit{From that point and onward, they are exacly the same.} Yet, this is conceptually speaking really all that differs between a a kernal with it's threads and any other normal program\ldots Imagine if you could have that while-loop, but just start the whole thing from within the first thread (or any of them for that matter).

	The rest of this text aims you convince you that these two graphs \textit{are in fact identical}, and to show how the "whish" just mentioned can be granted.

\section{The dispather}
	In reality, what differs between the first and second graph is a entity called the \textbf{dispatcher}. A dispatcher does pretty much what the program above does, excepth that it usually doesn't work with statically linked functions. Instead it uses \textbf{function pointers}. Have a look at the progam in table~\ref{hc2}.

	\begin{table}[!hbp]
	\begin{verbatim}
	#include "dofuncs.h"
	#define FOREVER 1
	typedef void *func_poiner();

	func_poiner fu_1;
	func_poiner fu_2;
	func_poiner fu_3;
	func_poiner fu_4;

	void dispatcher()
	{
	        while( FOREVER )
	        {
	                fu_1();
	                fu_2();
	                fu_3();
	                fu_4();
	        }
	}

	int main( int argc, char **argv)
	{
	        fu_1 = do_1;
	        fu_1 = do_2;
	        fu_1 = do_3;
	        fu_1 = do_4;
	}
	\end{verbatim}
	\caption{Soft-core shedule.\label{hc2}}
	\end{table}

	A function pointer is nothing but a variable that keeps the address of a function. Normally with the intention to also call those function, jaus as if they were any other normal statically linked functions. Many computer languages has similar concepts, but "C" is particulary easy to program concerning funtion pointers. (Btw, this happens to be what object methotds are In C++ - but that is a totally different story).
\\
	The program in table~\ref{hc2} actually defines a very simplified kernel. Only a few conceptual details are missing really. We'll cover them in later chapters. Until then, do please enter~\ref{hc2} in you computer and convince yourself that it really works.

\section{The schedule}
\subsection{A "job list"}
	What would happen if we instead of having separate variables for the functions were to put those in and arrary like in the picture~\ref{FunTable}?
	\begin{figure}[!hbp]
	\begin{dotpic}
		node [shape=record,fontsize=10.0,style=filled,fillcolor=yellow];
		edge [fontsize=10.0];
		graph [rankdir = "TB",fontsize=10.0];
		FunTable[label="do_1 | do_2 | do_3 | do_4"]

	\end{dotpic}
	\caption{Array of function tables.\label{FunTable}}	
	\end{figure}
	Then just imagine, we could change the order of their execution just by moving them around. Or we could increase one threads frequency by enering it several times in such an array\ldots We colud even make the array larger than needed and put some kind of a stopper at the end\footnote{These entities are commony known as \textit{"sentinels"}}. That we could alter that list whenever needed in run-time\ldots
	\begin{figure}[!hbp]
	\begin{dotpic}
		node [shape=record,fontsize=10.0,style=filled,fillcolor=yellow];
		edge [fontsize=10.0];
		graph [rankdir = "TB",fontsize=10.0];
		FunTable[label="do_3 | do_1 | do_2 | do_1 | do_4 | do_1 | \<NULL\>"]
	\end{dotpic}
	\caption{Reordered array. Notice that do\_1 occurs 3 times.\label{FunTable2}}	
	\end{figure}

	\begin{table}[!hbp]
	\begin{verbatim}
	#include <stdio.h>
	#define FOREVER 1
	#define NUMTHREADS 100
	typedef void *func_poiner();
	func_poiner furray[NUMTHREADS];

	void do_1(){printf("Run 1\n");}
	void do_2(){printf("Run 2\n");}
	void do_3(){printf("Run 3\n");}
	void do_4(){printf("Run 4\n");}

	void dispatch()
	{
	        While (FOREVER)
	                for(i=0; furray(i); i++ );
	}

	int main( int argc, char **argv)
	{
	        furray[0] = do_3;
	        furray[1] = do_1;
	        furray[2] = do_2;
	        furray[3] = do_1;
	        furray[4] = do_4;
	        furray[5] = do_1;

		dispatch();
	}
	\end{verbatim}
	\caption{Scheduled execution.\label{schedued1}}
	\end{table}
	
	If you want, you can try to modify the program and let one of the threads modify the shedule. Notice though that the thread\footnote{Our \textit{"dispatcher"} requires the \textit{"threads"} to be non-closed. I.e. they have to finish in one run} has to be open\footnote{This is still the case even in TinKer, but since we have multiple entry and exit points in TinKer, it's doesn't have to be from \textit{"start"} to \textit{"end"}.}.

\subsection{Some \textit{jobs} are more important than others}
A very common issue in control systems is the need to make a difference between the importance of certain activities. For example, interacting with the user can be considered less important than acting on a certain certain event. The less important activity can then be postponed or held back for a while until the important job has been completed.
	
	\begin{figure}[!hbp]
	\begin{dotpic}
		graph [rankdir = "LR",fontsize=10.0];		
		style=filled;
		color=white;
		node [style=filled, color=white, fontcolor=white];
		N0 -> N1 [label="priority"]
	\end{dotpic}
\\
	\begin{dotpic}
		graph [rankdir = "TB",fontsize=10.0];
		subgraph cluster_0 {
			style=filled;
			color=white;
			node [style=filled, color=white, fontcolor=white];
			N0 -> N1 [label="order"]
		}
		node [shape=record,fontsize=10.0,style=filled,fillcolor=yellow];
		edge [fontsize=10.0];
		graph [rankdir = "TB",fontsize=10.0];
		FunTable[label="\
			{ T3    |   T1  |   T7  | \<0\> |       |       } | \
			{ T2    |  T5   | \<0\> |       |       |       } | \
			{ T4    |  T6   |       | T8    | T9    | \<0\> } \
		"]
	
	\end{dotpic}
	\caption{"A two dimensional schedule. The 2:nd dimesion is our \textit{"priority"}.\label{FunTable3}}	
	\end{figure}


\begin{table}[!hbp]
\begin{tabular}{|l|c|c|c|c|c|}
\hline
		& Mon 	& Tue	& Wed	& Thu	& Fri\\ \hline
 8:15 -  9:00 	& math	&	& Phys	& prog	& play\\
 9:00 -  9:45 	& math	& music	& Phys	& prog	& play\\
10:00 - 10:15 	& hist	& wood	& math	& comsc	& elecronics\\
10:15 - 11:30 	& hist	& wood	& math	& comsc	& electronics\\ \hline
11:30 - 12:15 	& LUNCH	& LUNCH	& LUNCH	& LUNCH	& LUNCH\\ \hline
12:15 - 13:30 	& eng	& relig	& biol	& C++	& mechanics\\
13:30 - 14:15 	& eng	& relig	& bio	& C++	& mechanichs\\
14:15 - 15:30 	& art	& music	& chem	& Java	& rocket.sc\\
15:30 - 16:15 	& art	&	& chem	& Java	& rocket.sc\\ \hline
\end{tabular}
\caption{A school schedule inspired TinKer's schedule}\label{school_schedule}
\end{table}


The program in table~\ref{schedued2} shows you a simple example of how to implement and run this prioritized shedule. We're closing in on how TinKers schedule looks like. 

TinKers shedule follows the basic outline of our schedule so far very closely. However we can't use funtion pointers at each cell. If our kernel were to be running threads with a single point of entry and a single point of exit, then we could. But since we want our kernel to be able to do some other nice stuff\footnote{\ldots{}like sending and receiving information between threads using gueues, semaphores e.t.a.} we need to put something that holds all the information needed to do that. Whe need to put each threads \textit{envelope} there instead. We call it the \textit{thread control block} or \textit{TCB}.

Yet one more concept is missing. Not everything about the kernels behavior can be kept in the schedule. We need to applie certain rules of how to interpret it also. The understnding oan implementation of these rules are the job of the dispatcher. For example, the fact that the schedule is now two dimensional and that the second dimension is to be interpreted as the priority is such a \textit{"rule"}. 

How to implement such a rule can in turn be dictated by other rules. For example, dispatch threads at the same priority level in round-robin to give them equal chance to run. Handling of cases to avoud priority inversion could be another rule\footnote{Priority inversion can be avoided by temporary rise the priority of a thread to the same level as the highes level of a thread blocked on it. These advanced dispaching principles has not been adressed in TinKer yet.} 

TinKer has only a few of these rules, and they are hard coded in the logic of the dispatcher. In the litterature, one sometimes find expressions like \textit{scheduling techiques} and \textit{sheduling principles} used a little carelessly. I would like to point out that there is a difference between the rules of scheduling and the rules of dispatching. Many times when people talk about sheduling principles, they real mean dispatching principles. Using the correct terminology makes it a easier to know which part of the code in TinKer we're addressing\ldots

As a rule of thumb, everything involved with \underline{reading} the schedule and \textit{acating} based upon that added with additional logic is belongs to the \textit{dispatching domain}. Anything involved with permanently \textit{changing} the schedule belongs to the \textit{scheduling domain}.


	\begin{table}[!hbp]
	\begin{verbatim}
	#include <stdio.h>
	#define FOREVER 1
	#define THREADS_IN_PRIO 10
	#define NUMPRIO 3
	typedef void *func_poiner();
	func_poiner purray[NUMPRIO][THREADS_IN_PRIO];

	void T1(){printf("Run 1\n");}
	void T2(){printf("Run 2\n");}
	void T3(){printf("Run 3\n");}
	void T4(){printf("Run 4\n");}
	void T5(){printf("Run 5\n");}
	void T6(){printf("Run 6\n");}
	void T7(){printf("Run 7\n");}
	void T8(){printf("Run 8\n");}
	void T9(){printf("Run 9\n");}
	void NUKED(){}

	void dispatch()
	{
	        While (FOREVER)
	                for(prio=0;prio<NUMPRIO; prio++)
	                	for(i=0; purray(i); i++ );
	}

	int main( int argc, char **argv)
	{
	        purray[0] = {T3,T2,T7};
	        purray[1] = {T2,T5};
	        purray[2] = {T4,T6,NUKED,T8,T9};

		dispatch();
	}
	\end{verbatim}
	\caption{Prioritized schedule.\label{schedued2}}
	\end{table}
	This concludes the basic ideas that's the foundation of TinKer\ldots

\section{Yielding}
	The operation most assosiated with tdispatching in TinKer is the \textit{yield()} function as shown in table~\ref{yield}. Conceptually yield means \textit{telling the kernel that it might switch} me\footnote{I.e. the current thread} out of context and switch someone else instead if needed.
	\begin{table}[!hbp]
	\begin{verbatim}

	void tk_yield( void ){
	   TK_CLI();   
	   PUSHALL();   
	   TK_STI();

	   _tk_wakeup_timedout_threads();
   
	   TK_CLI();
   
	   //Do not premit interrupts between the following two. Proc statuses 
	   //(i.e. thread statuses) frozen in time.
	   thread_to_run = _tk_next_runable_thread();
	   _tk_context_switch_to_thread(
	      thread_to_run,active_thread
	   );   
	   POPALL();
	   TK_STI();
	}
	\end{verbatim}
	\caption{TinKer yield implementation.\label{yield}}
	\end{table}
	The yield function is called by all TinKer public API as a \textit{"side effect"} right before each function exits. The implementation of yield might differ depending on how the kernel is compiled. This example is showing yield as if compiled default. 

	Yield is what makes concurrency work in a non-preemtive environment. It can be seen a sort of intended interrupt, but one thats initiated by the executing thread\footnote{Which is not hown an interrup works}.

	The analogy is half bad, because two of the interrupts major properties are not there\footnote{Asynchronousity and externl initiative}. But the part that's conceptually equal is that when enter the function\footnote{The ISR is called} and if the system detects that our call (i.e. our imaginary interrupt) is a valid event, a certain thread\footnote{A certain routine will be preformed accordingly} will be started. 

	If there is nothing to be done, the program \footnote{I.e. our thread} will just continue normally. And this is also the situation when our imaginalry interrupt has completed.

	Using uield in your program is not natural, and normaly you wouldn't do that. Remeber, yield is executed for you and unless you have really long patchs of execution between entry/exit point's you don't have to call it.

	In principle, the same technique could be extended to cove each \textit{"C"} line in your code. This would be a kernel that has all the properties of a preemtive kernel, but without the drawbacks assosiated with stability and nasty bug crashes. This has to my knowledge never been done, the reason is the ratio between application code kernel which would lead to realy poor performance.

	As I allredy mentioned, yield can look different depending on how the kernel is compiled\footnote{This is handled by conditional compilation directives (\#ifdef)}  the version in table~\ref{yield}. The issue is wheter to use exlusive preemption\footnote{Build option '--enable-dispatch=EXCLUSIVE'} or not. If kernel is built that way, there is no need for yielding and the public yield will be replaced by a NULL pointer\footnote{I.e. any calls to yield wil be skipped}.

	Instead dispatching is expected to take place at the certain event's affecting our system. I.e. external interrupts or timer timeouts. 

	Please note, that your program can still look the same and you dont need to change anything. In principle you should be able to recompile and run yore application in one \textit{"mode"} or the other without any modifications\footnote{This assumes youre code is correct and doesn't rely on \textit{"side effects"} of any of the \textit{"modes"}}.
\\\\
	Previously I said that TinKer was very much influenced by the simple programs so far in this chapter. Yet, our yeid function doesn't look anything like a while loop does it? 

	It's true the function doen't have a closed loop \textit{inside}, but it's still there. The loop is extended outside, and if you envestigate the idle thread\footnote{A TinKer bases application usually has a couple af system threads. Two which are always present are \textit{"idle"} and \textit{"root"}.}, you'll find the loop there instead. See table~\ref{idle}
	\begin{table}[!hbp]
	\begin{verbatim}
	void *_tk_idle( void *foo ){
 
	   while (TRUE){
	      tk_yield();
	   }
	}
	\end{verbatim}
	\caption{TinKer indle thred.\label{idle}}
	\end{table}
	
	It looks like the loop is just extended one level. But do not missinterpret this by thinking context swiching can only occure here. This is just where it occures if all other threads are blocked. All threads are expected to interact with the kernel regulary by using it's API, and by doin this they will also pass entry/exit point's regulary where yielding will be also done.

	I.e. yeilding can occure at any levels and any priorities. It doesn't impose any restrictions on the caller, i.e. any thread can call it at any time. Wherter \textit{if} any action takes place or not is not for the caller to deside, only \textit{when}\footnote{I.e. at the point where the entry/exit point (or yield) is located.} it might do so.
	

\section{Who's the scheduler?}
\textit{This secion is an discussion about run-time vs. compile-time scheduling. It's intended for the advanced reader.}
\\\\
The process of "scheduling" is always a matter for the programmer in way or the other. This can either be in the form as the first examples in this chapeter, or more or less aided by the computer system the program will run ao. The former is known as hard-coded schedules and the second as soft schedules. 

TinKer is a soft schedule based kernel, which is the case for the majority of OS'es and kernels, even among those claiming to be addressing temporal space. 

No matter with type of scheduling techique your computer target provides, human intelligens is alwas at the top. Scheduling should at the very least be regarded as a combine effort by the programmer and the kernel. I.e. for a soft schedule based kernel, the programmer needs to know which API\footnote{API that will change the schedule are those involved in \textit{creation}, \textit{destruction} and \textit{priority changing} of a thread. A few imlicit situations will also change the shedule, like exiting a thread\ldots} will change the schedule.

\marginpar{%
\it{We'll use the terminlology hard schedule for hard-coded shedule and soft-shedule for run-time modifiable shedule. This might be the origin of the terms \textit{hard-} and \textit{soft real-time}, which is an un-fortunate usage of missleading terminology. This text will avoid using the terms hard/soft real-time.}
}

When the programmer \textit{"schedules"} a system design, he usualy would not use the same analogy\footnote{in the form of a "spread scheet" or "school schedule"\textit{}} as TinKer does. He'll probably use some formal methodology that eventually renders in a list of certain tasks and priorities. In some cases also perhaps a additional list of a sequence of changes to these priorities according to certain real world events 

When this program later executes, TinKers internal scedule will be affected in run-time accordingly and will reflect the programmers design in TinKer schedule form. I.e. TinKers schedule will be set when the program runs. 

The reason I mention this is that the process of scheduling can also be defined in compile-time. Some scholars in the area of real-time in the temporal domain prefere, that method because even the slightes change in the schedule takes a certain amount of time. In a fully temporal deterministic system you need to have control over \textit{ALL}\footnote{Soft scheduling in run-time might be deemed un-acceptable in certain cases.} aspects of time, including those modifying the schedule.

Whether this is good or bad, true or false is a subject of discussion that's been goin on for decades.

I do agree with the fact that soft scheduling adds complexity that makes temporal analysis more vounerable and less trust-worthy. But I would also like to point out the fact that this price for using hard coded sheduling tecniques is high and it's just not well suited for the majority systems.\footnote{There are some exeptions. For example control system where extreme safety is required. Extreme in this case, is a justified estimation between cost of lifes and cost of system} Don't make sloppy desitions regardin this matter, thinking "better safe than sorry"\footnote{Extreme case where hard-coded technology is chosen} or "let's wing it"\footnote{The other extreme case where soft a soft shedule is used}. If you don't know what your doing please \textit{RUN}\footnote{Both these cases are disasterous if desitions are based on the wrong asumptions or facts.}.
\\\\
TinKer provides a reasonable compromize and can address the needs of the temporal domain because $~{a)}$ the time involved in modifying the shedule is in most cases neglectable and in practice it $~{b)}$ either occure seldomly or in a very distinct patterns\footnote{The master-worker programming model is an example where the schedule will be heavilly modified in a deducable way.}. Furthermore you can $~{c)}$ read the code yourelf and deduct the times each shedule modifying operation takes. TinKer is also $~{d)}$ really not that complex, and it's not an impossible or impractical task to determine the execution flows involved with shedule modifications.
\\\\
What you should \textit{never} do if addressing the truly temporal domain though, is reliying on \textit{meassurements} and \textit{statistical} distribution. In that case you have left any aspects of real-time long behind you, since you're dependant of that ever so small chance that the unknown will happen. I.e. you're breaking the first principle of real-time - determinism.


%------------------------------------------------------------------------------
%------------------------------------------------------------------------------
%------------------------------------------------------------------------------
\chapter{Fundamentals}

	\section{Context and context switching}
		Before we go any further, we need to meention what is ment by a \textit{context} and what a \textit{context swich} is.
	
		\subsection{Context}
\marginpar{%
\it{Contex $\in$ Environment}
}
			The context you could say is the processors \textit{"environment"} - or more accuratly, it's not a property belonging to the processor but to the \textit{executive} (or \textit{execution entity}), which in a system without neither kernel nor OS can be regarded as the same thing. 

			It is the memory, certan states it has achieved and it's registes. The memory in turn can be divided in several part's. From a thread's point of view only one kind of memory matters and that is the part constituting it's stack. For fully fledged OS'es more than the stack would belong to each executing environment, it would actually have it's own set of all types of memory.
	
		\subsection{Context switching}
			\textit{Context switching} is a just what the words say: Swiching one envirnoment with another. In reality this is a little bit more complicated, but not much. Our context is the stack belonging to the thread. Almost everything we need to \textit{switch} is allready there. We only need to store the CPU's internal registers on top of that stack and we're prepared for the switching. The switcing itself is a very simple operation of getting the value of the CPU's stack-pointer (that will point to TOS), store that value away in a safe place. The the new theads stack pointer stored on another safe place and enter that value in the CPU stack-pointer itself.

			If that new stack is properly prepared, the rest will take care of itself. The registers will be restored with the ones previously saved on that stack, and when the execution will also return to the new adress stored in the new stack.
			

	\section{Processes vs threads}
		Both processes and threads are execution entities. They are conceptionally very similar, almost identical.\\
		\\
		Not to long ago I heard something funny. The Linux community had just recieved it's first implementation of a working POSIX 1003.1c complient kernel (i.e. kernel threads). The whole Linux community was praising this great innovation when some wize guy responded that \textit{"the embedded community has been able to do just that for more than 20 years"}\ldots

		Many times these entities were called something else, like \textit{ultra light processes}, \textit{tasks} e.t.a. In fact they were all really just threads.

		Thread had been possible to program for many UNIX systems for quite some time now. But threads were considered a property a a process (and still are in many peoples mind). Especially among the UNIX community this perception is very strong. This has probably to do with that the only way to achieve threaded applications was to link in a thread library. In most peoples mind this library wous somehow magically give the programmer threading abilities. For all what it seemed to be woth, thos threads shared the process environment, and threads \textit{"belongimg"} to one process could not easilly communicate with threads \textit{"belonging"} to another.

		There is no real or natural reason for this dependancy between threads and processes. Unfortunatly this has led to the missconception that this is the case. The only reason why this relation ever existed (because for all practical concerns it really did exist), was that the magic black box in the for of that library that was linked in was nothing else but a mini kernel in itself. I.e. each process would execute this own mini kernel that would in turn run all the threads.

		This is acually also possible with TinKer and some other embedded kernels (some coll it collaborate mode - I prefere not to call it anything since there allready exists way to many words and names and concepts). It's just a kernel executing in another kernel, nothing really magical about that. It could be recursed in arbitrary depths if one would want to.

		In reallity threads and processes are conceptually equal and dependency between them could either be there or not- That is totally dependant of the implementation. In Linux kenerl since 2.5.7 with the addition of kernel threads (which is a missleading name b.t.w. since one would imply they would execute as UID root, which is not accurate) a process can create threads without using an external library. These threads are scheduled in the kernel as if any othe process exepth that context swithing between them is much faster.

		Another disadvantage with the olde UNIX threading method was that time keeping was really bad. Suppose a thread were to go to sleep but during that time a whole new process would be switched into scope - this poor thread would have no way of regaining execution control no matter how imoprtant it would be. It would simply have to sit and wait untel the kernel in the OS would let the process that in run the kernel of that thread to regain control. In reallity this worked really badly and was almost useless. There would in fact be no particular advantages tread programming than program with processes, exept maybe that the API was a little better and easy to handle.



		\subsection{Threads}
			Both processes and threads are execution entities. They are conceptionally very similar, almost identical.

			A thead is just as I explained before, a just piece of that \textit{"sawing thread"}\footnote{The analogy with program threads as cut pieces of a swaing thread was first menioned in section \ref{genesis_thread} on page~\pageref{genesis_thread}.}, i.e. a small piece of the processors complete thread of execution. However, to be usefull it also has it's own context attached to it and the context to a thread is just it's own stack. On this stack, all local variables are stored there during is lifetime. Furthermore, when the thread is sleeping (or blocked as it's more accuratly called), the stack will also store a copy of the contents of all registes that the thread had before it was put to sleep. This is so they can be restored when the thread is later awankned.

		\subsection{Processes}
			Processes were to my knowledge actually invented before threads (or at least sort of).
			I believe that during the time the first multitasking execution environment was invented by the guys at AT\&T, it was believed that a process should have all the properties of a CPU. During early days, tools were quite imature and software bugs were not only frequent, they were also very hard to find. Also, since hardware were emensly more expensive at that time, one \textit{HAD} to share the processor with other tasks and stopping the whole system if one process crashed was avoided at all costs. 

			The only way to solve this was to separate each process totally from each other. The context was expanded to contain \textit{all} memory types including the code segment. Now, unless the bug was part of the kernel itself, all other processes could (in theory) continue even if one certain process failed.

			In practice this didn't work out all to well in all cases. For a certain type of systems, for example nationa database servers or registry accounting systems this would work fairly well, but for embedded systems a failiure in one part of the system would very often lead to a total system faliure anyway.

			The only way to make trully fault tolerant (and reliable) embedded systems seemed to be to distribute them. This observation in combination with the fact that processes are much more costly to handle (i.e. context switch, start and stop) led to the usage of threads quite early on.\\

			\framebox{%			
			\fbox{Theads and processes are conceptually identical.}
			\fbox{All that differs is that the process context is wider.}
			}\par

	\section{stack}
		Suppose our kernel would be implemented as the simplified kernel in chapter 3. If two threads would be executing the same function, both threads will share that functions local variables. This is normally not what we want. We want that each thread executes in it's own environment with it's own copy of any local variables.

		For that we need one separate stack for each thread. A stack is just a piece of memory somewhere intended to store local variables and function call return adresses.
		\begin{figure}
		\begin{dotpic}
			node [
				shape=record,
				style=filled,
				fillcolor=yellow,
				fontname=Courier,
				nojustify="true",
				fontsize=10.0
			];

			edge [
				color="red",
				fontname=Courier,
				nojustify="true",
				fontsize=10.0
			];

			graph [
				rankdir = "TB",
				fontname=Courier,
				nojustify="true",
				fontsize=10.0
			];

			stack [ orientation=73.0, label="{\
				..  | \
				..  | \
				TOS --\> var 1         | \
				var 2   | \
				..  | \
				..  | \
				var n  | \
				ret address | \
				arg 1   | \
				..  | \
				..  | \
				BOS --\> arg n }"];
		\end{dotpic}
		\caption{A typical stack. Adresses from top to bottom.\label{stk1}}
		\end{figure}

		With our a kenel or OS, a CPU would only have one stack\footnote{Figure~\ref{stk1} shows the principle of a typical stack, with low adresses from top to bottom. TOS is Top Of Stack and BOS is Bottom Of Stack. When function calls are made, the arguments are first put on stack, then the return adress. The function called upon is in turn reserving space for it's local variables on top of the same stack. A stack is said to grow upwards (imagine a hay-stack with more and more straws = data.) The order ofthe actual elements might vary depending on archetecture and calling convention.} which is set during initialization. When you have a kernel running, each thread (or process for that matter) will execute on its own stack. In principle all one has to do is change the stack pointer between all context swiches.

		From a concetual point of view, the stack concept is unimportant. You could in fact manage without all but the system stack (i.e. the one implitictly imbound by the fact that all CPU uses one), but it would be cumbersome to handle the mentined drawbacks. As a consequence, the stack concept is instead one of the most important entities of a kernel. We \textit{"only"} have to allocate some memory and to somehow attach that memory to each thread. 

		In theory this seems simple, but in reality this not trivial at all. This is also where most people fail, even if they've managed to come to realization as far as to this point. One of the reasons is that to do this operation is not "clean" i programatical terms. This un-cleanly ness shows istelf among others as need to implement parts in mashine code language and towards archetecture dependancy. However, how dirty this becomes depends on the implementation. TinKer's implementation is to my belief as clean as such an operation can possibly be, and it involves in best case only two lines of archetecture dependant code between various targets.

	\section{Time}
		The concept of time exists in many forms in a computer system: real-time, actual time, run-time, compile-time, clock, tick, RTC, process-time\ldots to name but a few. On-top of that, imagine that there exists different "schools" that oftem interprete one or more of these concepts slightly differently. The difference can be just a minor angel of view, but still have a very deep impact and concequence to the system that's based upon it.

		Time is both one of the best understood entities, and one of the most missued (or least understood) ones.

		To cover all aspects of time in a computer system, their meaning and implications would be daunting task, probablly well deserved of a paper of it's own. We're just going to coves some aspect's and what those means to our particular case.

		One major difference worth mentioning is the difference between how we humans perceive time and how comuters does is. We humans believe that we exist in a time continium. Some of us probably also believe that time itself must have started at some point, and that it will stop at some other point. Also, we humans have no real problem to conceptually understand infinilly small differences of time and that two events must be differentiated in time no matter how close to each other they come. One must have been first, and the other must have been second (conceptually we know this even if it sometimes can be hard to see wich one\ldots). We humans also ofthe relate to time as absolute.

		All of the mentioned aspects above have a totally different meaning in a copmuter. Abolute time for a computer does not exist without the help of an outer entitiy telling it so. Just imagine, for a computer all time is relative to one event - then the computer got powered on.

		The other problem for a computer is to implement infinity. A normal computer can't do that since each value has to be stored in some sort of variable thats bound by at least it's representation. It has to trade either resolution or span. What consequence does this lead to? Even though we in any normal calculations get alon very well with the value representations we have, time playes it's tricks on us. The reasons are actually quite obvious: 

		\paragraph{Drift} will be a consequence of limited resolution and accumulated error. No matter how small the error is, when infinity is a factor even the error will be infinite. Per definition it's therefore impossible to make any system that is without drift.

		\paragraph{Events} are actually a special aspect of time for a computer system. In many systems one can get away with not having any concept of acual time at all. The order of events could in that case be all we need to know. Some people even argue that time itself is just a continous steam of separate time events, appart infinitly close to each other. (We'll use this analogy a little bit later in this text, but for now I'll recomend you not to dwell into this). However, one problem even for events also stems from resolution. Since a copmuter has to work with slices of time above infinitly small, there is also the ability (or disability) not to be able to detect which of two event's that occured before the other.

		In other words: Time is not a very easy concept to make friends with for a computer system.


		\section{Dispatch \& shedule}
		In litterature concerning operation systems and kernel technology one often encounters these two words, quite often interchangeably. However they are not the same and in TinKer we've chosen to be picky about these two concepts.

		\paragraph{Shedule:} The shedule in TinKer is a two dimensional array, with priority in one dimension and execution order in the other. Quite similar to a school schedule actually, with days Monay to Friday horizontaly and time verticaly. In the cross-point of a certain day at a certain time one would get information what one is expected to do. The similarity with TinKers schedule is striking. In the crosspoint between a certain priority and the ordernumber of that priority one finds thread ID\footnote{A thread ID or TID is a handle to a task control block (TCB). 

		Each thread has one dedicated TCB and this  contains all information the kernel needs to handle the thread. The TID could be seen as an envelope, the TCB as the letter, and the content in that letter as the thread itself.}. Handling of the shedule is normally managed by the kernel itself and is called \textit{scheduling}. Sheduling is more or less planning the schedule, but not executing it. Many things affect the schedule, thread creation and destruction obviously, but also changing a process priority either temporary or permnently affects the schedule. A threads state does however not affect the shedule (i.e. wether a thread is blocked, ready or running), this is a matter of the TCB. 

		Some kernels have their shedules abstracted yet one level in queues, hence thw word ready queue, which simply means that all threads determined to be viable for executing are put in a FIFO queue. TinKer does not do this for the following reasons: The FIFO order is allready inbound in the schedule itself since the second dimension is the order to be executed in eaach priority. All we have to do is letting the dispatcher remeber which turn it had executed last time for each priority and then take the next one in turn. The second reason is that of speed and performance. If we were to have a queue, this would work fine if the shedule stays permanent. But what happens if the shedule changes and those changes happen to affect the threads in the ready queue? We would have to re-sort them every time and sorting is a relativly costly operation for a kernel not handling byt a handful threads.

		In big OS:es the situatin is different. There you would normally have thousands of threads\footnote{processes actually, but we agreed that these were concetually equal didn't we?}. Strange at it migt sound, sorting is relativly less costly if managing many threads due to optimizing algorithms. Also, the shedule itself will change relativly seldom, perhaps a few times per second. Whereas TinKer is made to be able to very effectivly run master-worker models\footnote{I.e. implicitly create a lot of small theads with a very short lifetime - this is the operation that by far is the most demanding on the shedule} and for that programming model to be any usefull we have to have a kernel designed to be effective for that.

		As a comparison, I once made a master-worker model inplementation sorting a text. It was a silly example, but each word got a dedicated thread whose sole purpose was to move the word it was resonsible for into it's correct place. We were litteraly starting and stopping several hundreds of threads per second. The same text was then sorted with the same program, one executing under TinKers control, the otherone under Windows\footnote{with a special POSIX adaption layer, called \textit{pThreads Win32}.}. Guess which one was fastest? Sorting under TinKer took less than 1.5 seconcs, whereas the Windows version took more than 27 seconds. Worth noticing is also that the CPU where TinKer was executing was a 40MHz XC167 nd the Windows one was a 3GHz P4 (!).

		In other words, some really beautiful programatic concepts you can \textit{kiss bye-bye} on a system not well suited for it (which is a shame really).

		\paragraph{Dispatcher:} The dispacher is a piece of code using the schedule. The shedule is it's "rule set" and the dispacher dispaches the work based upon it. It does this by determining which thead is supposed to run next and also executing the actual context switch. One says that threads are "dispached" according to the "schedule", i.e. they are executed one after one in an order determined by the contents of the schedule.
		
		In TinKer additionaly keeps track of a order counter beloning to each priority. It does this so it can dispach work evenly anong threads within the same priority. This is needed to avoid the need of a ready queue.

		\section{events vs time}
		events vs time

		\section{Entry and exit points and yield}
		If we were just to start threads, the them execute until they're finished and the die by them selfes life would be realy easy, and writing a kernel would indeed be possible to do in 30 minuts.

		Even thoug we \textit{could} write our programs for that type of kernel, we normally wouldn't want to\footnote{actually, at least one very obscure kernel actully expects programs to be written thit way.}. The reason is very simple but perhaps not so obvious. It turns out that it's just much more convinient to have threads living longer than just a fraction in time\footnote{Real-time temporal domain analysis using rate.monotonic is especially suited for this type of kernels} and it makes programming much more intuitive. The trade-off urged by the real-time gurus belonging to the temporal school is that you will not have control over which execution path each thread takes.

		This is however easilly overcome by programming dicipline. If you absolutly must handle temporal real-time requirements in software, you'd be really silly if the thread handling that requirement would be complicated. Besides, theres nothing stopping you using a thread with a body with only starte and exit\ldots

		Entry end exit poit's are places in the threads body\footnote{The function each thread operats on we call the threads \textit{body}. Note that several threads can share the same body. The body is only the rules for what to do and nothing else is shered excepth that. Each thread will have it's own copy of each bodies local variables.} exepthe the obvious ones (entry and return), where ther thread can get in and out of execution. 

		These points are in TinKer most of the function calls you'd use. This is also why the kernel works evein on systems unable to preemt. A real time kernel kernel colus manage without entry and exit points, but then it would have to base all it's scheduling on preemtion. Simulation such kernels would be wery hard and debugging them close to impossible\footnote{I know this the hard way. Tinker is my third attempt, and both predecessors were fully preemtive and peeemtive only kernels}. 

		In TinKer we actually have a choice to have preemtion ebnabled only, never have it (i.e. dispaching only inside entry and exit points) or both. Each mode has it's strengts and draw backs, the combination of both potentionally enables us to have the best from both sides.

		\paragraph{Yield} Or yielding\ldots there is a special function intended \textit{only} as an entry/exit point and this one is called \textit{yield()}. It basically does nothing except calls the dispatcher\footnote{In thinker the dispatche is not a stand alone entity and the yield() function is actually part of the dispatcher}. 

		One normally uses the yield() function in parts of the code wher you know execyution has been going on for long without the hernel having had a chance to try to detect id some other thread is ready to run. Explicit yielding is quite un common\footnote{This is due to the fact that most applications will let it's system become idle most of the time. What better to spend that time than to let an dedicated idle thred run the dispatcher over and over again?} and the other API is normally qiite enough. Exeption would be in loops or othe programatical constructs where the CPU would spend a lot of hard run time.

		

		
%------------------------------------------------------------------------------
%------------------------------------------------------------------------------
%------------------------------------------------------------------------------
\chapter{A thread comes to life}{
A thread comes to life in two stages. The creation of the thread and the staring of the thread. It's important to realize the difference between these two. This chapter will focus mainly on the creation. Start of the thread is covered in the chapter Dispatching in \ref{FIXME}.

\begin{itemize}
	\item Creation of the ctread involves allocating and binding it's context. It also involves preparing each threads stack, so that it will be ready for dispatching.
	\item Staring of the thread is done asyncroniously by the dispatcher. The dispatche will start the thread whenever it's run and whenever the schedule and priorities are proper for the thread to execute. The dispatcher doesn't know if what it's dispacing is just starting or has allready been executing a while.
\end{itemize}

As allready mentioned, a thread can be viewed just as a sort of a function\footnote{This function(s) we call the threads body. A bodies can be shared among threads.}. Or more precicely a function \textit{call}\footnote{because the thread is really an execution \textit{path} and not the function itself}. The only thing we have to do with it is attach a stack to it and we're ready to go. Or is there something else to it?
\\\\In principle, no - in practice, this is easier said than done!
\\\\The task of designing TinKer can be summarized into only 2 questions\footnote{The solution of each problem starts by knowing how to put the quiestion.}:
\begin{itemize}
	\item Remeber the little wile loop in our first program in table~\ref{hc1}\footnote{See page~\pageref{hc1} }? How can we make something that executes the same way, but doesnt start from within the inner loop?
	\item How can we attach a context to a tread\footnote{I.e. how can we connect a thread with it's stack}?
\end{itemize}
It turnes out that the solution of both these questions depend on each other. I started by adressing them separatly and furtunatly I found a soultuion that satisfied bothe. I guess I was lucky\footnote{But not really...}\ldots


\section{Creating the thread}
\label{MakeOfThread}
	TinKer actually started as the program in table~\ref{hc1}. For quite some time I was fashinated by the beauty and simplicity by it. My previous kernels were much more complicated in this certain aspect, and I couldn't get rid of the idea that if I just could let that inner loop fe a function somewhere else than in the main scope, I should be able to dispach with exactly the same code. Guess what? It was possible!

	\paragraph{Resource allocation} 
		Creating a tread consists of two parts. Allocating the threads resources. This involves getting (or allocatin) a TCB\footnote{Task Control Block - the threads \textit{"envelope"}}, allocating a stack and binding the thread, the TBC and it's stack togeather.

	\paragraph{Preparing it's stack} 
		Before we can run the thread we need to prepare it's stack. To realize why this is nessesary, one must realize the very tight relation between this part of the threads life, and the dispatching\footnote{We'll cover dispatching in more detail in \ref{FIXME}} of threads. The stack, or actually the upper part of it, \textit{must look like as it would if the thead was swaped out after a context switch}. The reason beeing that it is the dispatcher that starts the thread and it doesn't do this any differently than any other normal context switching.

		In the preparation of the TOS\footnote{TOS (Top Of Stack) is used gereracly as a term to refer to the whole upper part of the stack, not just the most topmost address}, three parts can be identified\footnote{It's not nessesary to make this separation, but it makes a difference on the implementation since each of them implies certain special ways of solution}:
		\begin{itemize}
			\item Pushing the CPU current registes on TOS\footnote{Technically speaking this is not required, we only need to move the SP the corresponding distance to satisfy the reversed operation of the dispatcher}. We use the same routine that the dispatcher would use for half a context switch. This makes it easier to make certain that the stack looks the same the dispatcher would have left it after a context switch.
			\item Putting the return adress to the start of the threads body at the correct place.  Put the threads starting arguments on the stack. \footnote{This step could be viewed as two parts (or steps), but they are so tightly coupled togeather that proplems/solutions related to one olso implies/affects the other. They belong together\ldots}	
			\item Copy the content of the CPU's current\footnote{I.e. after the above operatiuons. Order is very relevant} SP to the TCP's corresponding variable. \footnote{This involves only 2-3 lines of code, but gas nevertheless to be written in assembly.}
		\end{itemize}
		These operations are made by a set of macros, why? Two reasons: $^{a)}$ The same reason as any normal progrem, you want to increse the abstaction level and thereby make it easier to read and logically grasp the code. Normally one would use functions for this\ldots $^{b)}$ Using functions would however be be awkward (if not impossible) since they them selves operate on the stack\footnote{Functions use the CALL operation, i.e. they PUSH, POP and RET on the stack. Also note that tool-vendors do not lay out the "call stack" exctly alike.}.

		The choice is between hard coding this whole part of the kernel differently for each target, or to use macros as a fair compromise and just hard code those macros differently.

		During the evolution of TinKer the steps above were refined one by one and in innovative jumps. From having to implement all of the steps in hard code, to succesivly make each of them simpler and simpler. That todays latest technology in practice only needs to adress the last point.\footnote{This is experimental as of this writing. But it's seems very promising and if it turns out OK - crude porting of TinKer to a new architecture would be really painless (days, \textit{not} weeks or months) and porting to virtually hundreds of CPU's would be managable even by a small group of maintainers.}

		
	\subsection{Moving forward, by going backwards}
		To see the problem in the first question, consider the two programs\footnote{These are greatly simplified and would not work in reality. They just serveto exemplify the question.} \ref{hp1} and \ref{hp2} and ask youself what the difference between them is and how we can make \ref{hp2} work. One thing is obviouslly different. In the series of function calls, the last one is replaced with main\ldots

		If we were to look at the stack\footnote{so far we have only one stack, the system stack} in the middle of execution, and compared them with each other, we would find out that they are surisingly alike\footnote{As a matter of fact they are conceptionally identical}. If we could just somehow get our program counter inside the loop in \ref{hp2}, the execution flow and the stack comparismet would be exactly the same. However, our programming language doen't seem to allow us to jump right inside. Actually, here is the first obsticle\footnote{You can't use C everywhere if you want to design a kernel.}, we need some sort of trick\footnote{But you should try very hard to use C as much as possible}. It seems obvious that we need to use assembly language to solve this problem. But should be just jump? And where to BTW, we don't seem to have a lable to jump to and surely we can't be expected to edit the output of the compiler just to add a lable each time we want to start a new thread?

	\begin{table}[!hbp]
	\begin{verbatim}
	#include "dofuncs.h"
	#define FOREVER 1
	int main( int argc, char **argv)
	{ 
	       while( FOREVER )
	       {
	                do_1();
	                do_2();
	                do_3();
	                do_4();
	        }
	}
	\end{verbatim}
	\caption{Hard-core shedule.\label{hp1}}
	\end{table}

	\begin{table}[!hbp]
	\begin{verbatim}
	#include "dofuncs.h"
	#define FOREVER 1
	int dispatcher()
	{ 
	       while( FOREVER )
	       {
	                do_1();
	                do_2();
	                do_3();
	                main();
	        }
	}

	int main( int argc, char **argv)
	{
	       while( FOREVER )
	       {
	           yield();
	       }
	}
	\end{verbatim}
	\caption{Crude dispatcher and yeld.\label{hp2}}
	\end{table}

		No, we don't want mess with that\ldots The answer lays in how the compiler executes a call\footnote{Hmm, lets see\ldots what is it that's different again?}. 

		Simplified a call to a function is done by a \textit{CALL}\footnote{some CPU architectures don't have any \textit{CALL} in their reportoar. The compiler will in that case construct a series of operations with the same effect based on for example \textit{JUMP}} instruction. This in turn leads to that the next address to be executed \textit{after the function is complete} is pushed on top on the stack. The CPU then jumps to the function and starts execution. 

		When the function is complete, the CPU executes a RET, which just fechest the adress previously PUSHED by the CPU and enters that address into the program counter\footnote{The end result of completeing this instruction cycle is that the CPU continues execution beginning at the address now in PC}-

		Howabout if we reserve this order in which a \textit{CALL} is executed? Let's try mimicing how a compiler would lay out the instructions . \textit{BUT} the other way around! Lets call the function by pushing it's adress ontop of our stack and then exacute a RET instead. Now why on eath would we want to do that? 
		tBecause $^{a)}$ we actually don't need to execute that RET\footnote{This will be done automatically when we exit the scope of the \textit{current} function} explicitly, and $^{b)}$ we can postpone the start of execution by letting the dispatcher \textit{start} the tread for us. The dispatchers job is just too seek up theads to run and then to change the context from the running one to the one to be run. 

		The beauty of it, is that \textit{the dispatcher doesn't know} that it's actually also \textit{staring} execution of threads now and then. All it does is enter a function called yield() and when that funtion \textbf{\textit{}RET}urns, the new thread will start executing. 

		This way a thread can be made to obey priority from the very beginning. I.e. if a thread is created with a priority less than the one of it's creator, it will \textit{not} start until the creator is ready to become blocked, thereby we don't create priority inversions\footnote{An unexpected bonus is that it virtually doesn't take any time at all to create threads. Time for cration and destruction doesn't have to affect the creator of the thread, who most oftenly is also a thread. Nice, we can now implement master-worker model based applications and don't need to rule this beatiful programming techique out because of poor performance!}. 

		In principle, all we need to do is pushing that adress and the rest will take care of it self. Oh and yes, before we do that we also need to change the stack...

	\subsection{We need our locals}
		The second major problem was to attach a context for each thread. This is honestly not very hard at all, but we need another trick. The context for each thread is expected to be reached by \textit{one}\footnote{and one only \ldots} variable. This happens to be prepared by most CPU's allready and is called the CPU's SP\footnote{I.e. the CPU's \textit{stack-pointer}. This is a special register in the CPU that constantlly points at TOS (Top Of Stack).}. So our context is pointed out by this SP?

		Not quite, but almost. Each thread has a TCB\footnote{Task Control Block, see \ref{FIXME} which is struct holding several variables. The most importan of these variables are each threads SP\footnote{Actually, a copy of each threads SP as it were just before it got blocked. The real SP belongs to the CPU and there can only be one\ldots}} and this is the \textit{key} to the threads context.

		So what we do is\ldots 
		\begin{itemize}
			\item We allocate some memory\footnote{We use kalloc for this. See later chapters regarding problems with stdlib and multithreading \ref{FIXME}}.
			\item We take the adress of the last byte in that chunk of memory, and put this value into the threads SP \textit{copy} in it's TCB.
		\end{itemize}
		That's really all! Now when the dispatcher runs, it will find the thread to run\footnote{which in this case happens to be a newly created thread that wants to enter it's body}. it will look up that thread's context from the threads TCB and it will simply enter that value in the CPU's real SP. The top of that thread has allready been prepared\footnote{because we changed the stack to this one for a moment when we created the thread.} with oll le local variables, but most importantly \textit{with the return adress} that is now used to enter our newly created threads body for the first time.

	\subsection{Why not facing front}
		Our thread staring technique\footnote{See \ref{MakeOfThread}} so far is elegant. It's very fast and it's quite\footnote{Well, sort of\ldots Very few but lines, but pure murer to implement} easy to implement. But is has a few annoying drawbacks, that all stems from the common determinator that the preparation of each stack before a thread can be run. It involves only a few lines\footnote{Typically between 50 and 250 lines of assembly}, but lines wery hard to write. The reason was that besides having to learn each archetectures assemby language., I allso had to cope with different varians depending on the toolchain. And I had to lern each combination of tool-vendor and archetecture there particular methid of calling convention\footnote{Once upon I time I thought there could be only one way. I soon learned that there are many\ldots (similar most of them, but still not quite equal)}. Added on top are the following differences concering preparation tof the top of the stack:
		\begin{itemize}
			\item They differ between archetectures
			\item They differ between tools-chains (even for the same archecture)
			\item Calling convention might differ even for the same tool chain depending of how the tool-chain was compiled\footnote{I.e. which ABI it was configured with (ABI means Aplication Binary Interface. COFF is one example, ELF another)}
		\end{itemize}
		For a long time I thought I could not possibly make the abstaction of a thread creation and dispatch any higher, and that this dependancies and obsacles would have to remain. I had to spend a few weeks to a 1-2 months for each archetecture port, but it was still much better than my previous two attepts. 200 hundred lines of assempby code, how hard could it be\ldots

		The problem was not how hard it was. I could live with the fact that it took a while to create each crude port \textit{once}, but the maintenence issue was scary. I had by then TinKer allredy running on 6 different targets, and the time I ended up spending tuning and adjusting these lines soon became predominant. Also TinKer was very vounerable for any small change the tool vendor came up with and I had to re-validate TinKer for each version of each tool-chain.

		There had to be a better way\ldots

		So I begun experimenting with the thread creation again. It turned out that I could let the comiper and CPU in combination set most of the stack up automatically. The solution was not as elegant as before, and I had to trade away a little time upon each thread creation\footnote{The automatic set-up is made by letting the thread execute for a short while. I'e \textit{"compile time set-up"} was traded for \textit{"run-time set up"} }

		However, the number of difficult lines dropped to $1/5$ of what they where, and since I was spending most of my time in this jungle, I suddenly got much more time left for doing the fun parts.

		\paragraph{This is how the new techique works\ldots} 

		\paragraph{What about preemption?\ldots} 

	\subsection{Yet some improvements}
	\textit{This section descripes an area not yet fully prooven.}\\\\
		During my contributing work for the GNU tool-chain, I had to implement some obscure functions called \textsl{setjump} and \textsl{longjump}. I've seen and read about them before, but they seemed awkward to use. Furthermore, they seemed to focus on error handling and other boring stuff. However, they were part of ANSI so we\footnote{i.e. the gange helping out porting the GNU toolchain for \textit{Blackfin}} had to implement them. They were always also written in assembly because what they do is saving and restoring the contents of a CPU registers, which differs between archetectures.

		Besides from a tiny little jump in both of the routines, they seemed similar to my \textit{PUSHALL} and \textit{POPALL} macros. Actually, they were conceptually equal\ldots and they are part of ANSI\footnote{I.e. No matter version, tool or vendor, you should \textit{always} have a working set, adapted for the CPU architecture and any imaginable variants of that acrhetecture}\ldots
		\\\\
		HEY!\footnote{If it proofs to work out all right, a crude ports will only differ by two lines of assemby between each other. Suddenly all the ports the GNU tool-chain supports is also potentially availabe for TinKer!}

}%Chapter

%------------------------------------------------------------------------------
%------------------------------------------------------------------------------
%------------------------------------------------------------------------------
\chapter{The kernal scope}
The kernel scope is the adapted environment that makes dispaching, and sheduling possible. It is the outer bounds in whichthe CPU executes.
\\\\
This sounds rather pomos, but it's really just the whole \textit{"program"} as seen by the CPU. 

Remeber I said that there is "no difference between a normal program and a threaded program, it only apperars that way"? This is part of what the kernel scope is.

The kernel scope would be best understood if viewed from two perspectives: CPU and kernel.

\section{CPU perspective}
	From the CPU perspective the kernel scope encapsulates the tinker kernel and all it's threads. It's \textit{the program itself} and could be compared with a \textit{process}. Except that most target's that TinKer is supposed to run on doesn't have any 

	If anything shold be called a process it would be the CPU bare-boned execution environment itself, i.e. the \textit{processor}. 
	\textit{process}.%
	\marginpar{%
	\it{processor = process}
	}%
	However, when you run any TinKer based application under for example Linux, the application will indeed execute in a process of it's own - i.e. a Linux process in that case 

\section{Kernel perspective}
	From the kernel perspective, imagine what the kernel would need to be able to run at all. We say that to be able to execute, we need to instantiate the kernel. This is consists of the following tasks.

	\subsection{Allocaton}
		One of the design philosofies behind TinKer is that the kernel shold not rely on any specific standard library\footnote{it's shouldnt trust any either}. However, we don't whant to reemplement everything either and would like to take advantage of whatever support the standard library can give us.
		\\\\
		What's the problem then? The problem is that standard libraries doen't normally consider any concurrency or multitasking. Furthermore if any particular library do, it's alwas tightly coupled with a certain kernal. We don't want to reemplement any stdlib, basically beacuse in the case of the client using comesial tools we can't (or we would have to rewrite the whole thing), and in the open source case because we would have to administrate, manage and maintain patches witch is a lot of work. So what we do is \textit{coping} with the standard library you're using.

		The only thing that's in the way of using \textit{any} working standard library, is the matter of concurrency. I.e. if we use the library in a non-concurrent way we're OK. This is what TinKer does. \textit{TinKer \underline{preallocates} any resources it needs, and all the resources the application is expected to need\footnote{This is the reason why TinKer nees all those configuration parameters when you build it.} before execution of the application is started. These resources are then handled internally by TinKers own API, which takes care of any concurrency issues.}

	\subsection{Set up}
		When all the resources are allocated, we need to set the kernel up. This involves clearing the schedule, initializing all TCB's in the pool and to create the idle thread.\marginpar{\it{main resource = stack = memory}}

		Now the current thread of execution (i.e. the CPU total thread of execution) is \textit{"re-assigned"} a context making it appear like any other thread that can be part of our schedule\footnote{Now two threads are in the schedule, idle and root}. This "thread" will be named specially and called "root" and will be given the system highest priority\footnote{Thereby guaranteeing execution until the user program starts it's own first thread}. It's resources will also be based on what was available in the kernel scope, and not allocated as for the rest of the threads\footnote{I.e. it inherits the stack from the kernel scope}.

		Last of all the root's body is entered. This function is expected to be named \textit{'int root()'} by the linker, but is converted by a macro trick to look like any normal program entry point, i.e. \textit{'int main(int argc, char **argv)'}. 

		I.e. youre program can use either of the two, but it must have one. I would recomend to use the second notation because it makes your program directly portable to any othe POSIX environment.




%------------------------------------------------------------------------------
%------------------------------------------------------------------------------
%------------------------------------------------------------------------------
\chapter{Dispaching}

\begin{figure}[!hbp]
\begin{dotpic}
	node [
		shape=record,
		style=filled,
		fillcolor=yellow,
		fontname=Helvetica,
		nojustify="true",
		fontsize=10.0
	];

	graph [
		rankdir = "LR",
		fontname=Helvetica,
		nojustify="true",
		fontsize=10.0
	];

	edge [
		color=black,
		fontname=Helvetica,
		nojustify="true",
		fontsize=10.0
	];

	Dispatcher -> IO		[label="You're next"];
	Dispatcher -> Console		[label="You're next"];
	Dispatcher -> Application 	[label="You're next"];

	IO -> Dispatcher		[label="Yield me"];
	Console -> Dispatcher		[label="Yield me"];
	Application -> Dispatcher	[label="Yield me"];
\end{dotpic}
\caption{Dispaching inprogress\ldots\label{disp1}}	
\end{figure}

\section{Where, what, who?}
Dispatching is the activity where reading \& interpreting the shedule and context switching takes place.

So far we're talked about \textit{"dispaching"} and \textit{"the dispatcher"} as if there were a certaing inity in the kernal for that. It doesn't\footnote{At least not one dedicated entity}\ldots

Certanly a kernel \textit{could} have a dedicated dispatcher, and I'm certain that some kernels do. It outlines a very nice abstaction and it could be implemented more or less eactly as our very first imaginary kernel in in table~\ref{hc2}.

However, though this seems nice in principle, there are a some penalties to be payed if implemented that way.
\begin{itemize}
	\item $^{A)}$ The dispatcher would have to have it's own context
	\item $^{B)}$ It would have to run at well defined occations
	\item $^{C)}$ It would have to run at highest priority
\end{itemize}
Alltogeather, this creates a rather clumsy runtime behaviour. Unnessesary time would be spenc running the dispatcher when it's very probably not needed. It would also \textit{require} peemtive run-time behaviour, thereby makeing it much more difficult to run the kernel in a simulated environment.

When the process\footnote{ment in it's litteral sence, i.e. not as a operating system process} of dispachting takes place can be divided in the following three philosofies\footnote{This is one of the most important foundations for any  kernel and will have one of the greatest impacts on the design}.
\begin{itemize}
	\item On a regular basis, often driven by the system \textit{"tick"}footnote{Usually as part of the timer interrupt which otherwize only incriases a counter called \textit{sys timer}}. I.e. time is regarded as an series of events with a certain granuality, and the dispatcher is driven by those events.
	\item Similar to the above, but more generalized meaning that evry outside stimuli (i.e. interrupts) will run the dispatcher. This is the case in traditional real time kernels. Note that time could, but doesnt have to, be regarded this way. When you have the abiliies to run the dispatcher on other stimuli, you dont need the time to help you cut the CPU's total thread of execution in pieces any more. Wheather it's done or not is implementation specific for your kernel in question.
	\item The appliction (i.e. the threads themselves) desides when and where. This is done by explicit calls to a certain $yield()$ function, or by entering certain entry/exit functions\footnote{Usually all of the kernels public API is a potentila entry/exit point.}  This is called \textit{explicit yielding} dispatching.
\end{itemize}

Which of these philosophies to use depends on what type of kernel you want. All of them can potentially satisfy the first part of the real-time paradigm. But not all of them can satisfy requirements in temporal space. TinKer uses all of these philosophies, but with an empesize on the last one. The main difference between the first two and the last is that the formers leads to preemtive behaviour and the latter does not. 

Many kernels follow one of the above philosophies quite stricktly. The reason being that each method affect the design very much deep down in the kernel. Their respective solutions don't have much in common either\ldots. However, one doesn't \textit{have} to rule one on behalf of another\textit{theroreticaly speakin}. Question is rather if it's pracicaly possible \& justifiable or not. 

\textit{Explicit yielding} is the fundamental type that formed the design of TinKer. It turns out that going from this type of kernel dispatching towards any of the other two is much easier than the other way around. One will end up with a quite lot more code than if any other would had been addressed specifiacally and exlusevly from the start, but the code is quite readable\footnote{Going the oposite direction would be a complete mess to say the least.} and trading between readability and effectivity alwas goes in favour to readability\footnote{Many will not agree, but use common sence and ask youself: How many obscure OS:es or kernels out there do you know that's survived more than 2 decades?}. Focusing on readability leads to mainainability, and if some speed or effectiveness (if any) is lost that way, so be it. Computer hardware has a tendency\footnote{This interesting \textit{"fact"} has been true for more or less as long as computers has existed} of doubling it's performance by 100\%  each 18'th mont but a kernels dispaching method will stay static for it's entire life span.

The design of TinKer is influenced by the  empirical observation, that of that most of the time a computer system runs, it does nothing but sit's and waits\footnote{I.e. executes in the \textit{idle loop}}. I figured, jjast as it sits there in a emty while loop doing nothing, it's might just as well do something most of the time equally unnessesary. Why not \textit{"dispach"} there instead over and over.\footnote{In the idle loop? You must be crazy - this can't work!\ldots}

If this were the only place dispatching would take place, this would obviously not work very well. Fourtunatly this is not the case either. Dispaching takes place on many places\footnote{Depending on how the kernel is configured: Peemtive only, non-preemptive or combined}, most notably is at the \textit{entry of each exit-point}. I.e. evry time you code is making a system call that belongs to TinKer, the dispatcher is run. This is what makes concurrency in non-preemtive environments.

All these calls have one common dominator, and that's the yield function\footnote{more or less embedded deeply in each function}. Yield is where the actual dispaching takes place but you still can't call it the dispacher because it belongs to no-one and enyone can call it. I.e. dispaching is a property of the whole compined system \footnote{I.e. the kernel and it's threads}. If some entity would be pointed out as a dispatcher, it would have be the whole kernel. Notice the two main properties of the dispatcher
\begin{itemize}
	\item Determining who's next to run and run it\footnote{i.e. context swith to the thread in question}.
	\item Repeat this in a never ending loop
\end{itemize}
The only practical difference between TinKer and the small little example in table~\ref{hc2} is that this loop is extended. It's still never ending though\ldots

\section{The sleepwalker}
This method of achieving concurrency seems really silly doesn't it? TinKer claims to have real-time abilites and very fast response times, so how can this be even remotly possible?

First of all, running yield function is not as costly as one would think. Naturally doing it to often would put an unhelthy ratio between CPU time spent in the application and in the kernel, but you won't in most cases.

To realize this you have to realize the difference between the execution path and the program code. The distance between two entry/exit points might seem close in your program code, but in reality they are relativly speaking usually very far appart.

The second thing that motivates this type of kernel is based on the same sleep observatin as mentioned before. It is very likly that whenever something happens\footnote{I.e. when an event happens per definition} that the CPU will be executing in the idle thread happily executing yields all the time. I.e. the probable response time will be lightning fast since we don't have to wait for the dispatcher to specifically be run.

\textit{\textit{"Probability"} based execution! But what about that \textit{"real-time"}?} Here's where the kicker line comes in: Speed and response time hasn't anything to do with real-time in a system not having temporal recuirements. Only event's matter and the order between them. This is quite likelly the only think you need\ldots

There are a couple of really big advantages using non-preemtivive dispatching.
\begin{itemize}
	\item It's much easier to debug (compare preemptive debuggubg as trying to debug interrupt functions). It's very hard and human error and further conclusive misstakes are eminent.
	\item A preemtive kernel never 100\% safe. Reason is that it's very hard to make a good compromize between where interupts might occure, and where they must not. Playing it safe but by disabling too much would lead to poor behaviour, opening up could mean you miss a spot that's critical. This are is furthermore complicated by the fact that while inside the kernel, the kernal can't use it's normal protecting mechanisms. It's has to relie on HW disaling of interrupt's and this is awkward\footnote{The awkwardness is due to that if you want to open up preemption in some sort of complex part of the kernel, you almost always need to know the state of the interrupt disable flag. However, determining this will take yet a few cycles during wich time another interrupt migh have occured. How do you know wich? Some HW hae support for atomic operations of read-modify-write settings of flags however.}.
	\item From practical experiance, I know that beeing able to run a control application in a simulated environment is a big advantage. Depending of the application the possibility to do this varies of cource, but it's usually much more common that you'd think\footnote{Consider if you application has parts that could be run in simulated environment even if other parts can not}. The ability to ru in a simulated environment is usually very rewarding and your investment in terms of adaption and set-up time is normally payed back with enourmous profit.
\end{itemize}

\section{Have it your way then}
However, should you have temporal requirements - TinKer can satisfy these too. You would have to start using interrupts however. If you feel confident with that, then there is nothing stopping you.

Whn you start use TinKer in a premtive way, you will be able to adress temporal space. But also please note that the response times will resemble those of a normal kernel much more. No more light speed response times with optimistic success rate. Instead you'll get a little slower but deterministic temporal behaviour.

When TinKer is compiled without any options regarding preemtiveness, preemtiveness is actually enabled. Wheter you use it or not depends if you use ISR's that call TinKer kernel API.

However, if you plan to use TinKer for temporal requirement I would suggest you compile it with with peemtivenes exclusive\footnote{Build option --enable-dispatch=EXCLUSIVE}. The reason is that you don't benefit from \textit{using} both preemtiveness and non-preemtivenes behaviour at the same time.

What will happen when the kernel is built that way, is that several of the kernel API that were previously also entry/exit functions will obandon that duty and do \textit{only} what their definition says. This leads to that execution time for each thread from event to response is much easier to deduct (and that's what you need to formaly validate your temporal requirements).

The time keeping function will also change to the \textit{PTIMER} module instead of the \textit{sleepy timer}\footnote{\textit{PTIMER} is a preemptive timing technique, whereas \textit{"sleepy timer"} is poll based}. Last but not least, it will lead to that the idle loop will not execute yields anymore, thereby making sure that the time spent in the kernel by the CPU also become minimal and deductable. 

I.e. the CPU will execute inside the kernel only when you tell it to, and time for each execution path can be determined and entered in you rate monotonoc analysis.
\\\\
I would urge you to carefully consider if this is for you. True temporal domain problems are something for experts.

Yet another aspect is the following, which is the same reason why tru temporal reqirement applications are quite uncommin in the UNIX world\footnote{Relatively speaking but even among control applications}. Temporal space is a matter of the whole system. The more comlicated the system is, the harder it is to verify. Do you have control of all parts? Are all threads in you're control? Do you even know about them? Can you trust the execution environment?

I.e. even if your timly analysis is OK and you can formally prove your timporal requirements, it's still possible you've missed something that will crash your timeliness, and furthemore: you'll not know it unless it's happening\footnote{I.e. too late}.

So unless you're not 100\% certain you have full control of each part of your system, I would urge you to rethink.

I'm not joking, but the 30 minut kernel might not be such a bad alternative afterall\footnote{See \ref{kernel30}}.

\section{Preemtion, events and other stuff}
\marginpar{$Preemption \ne ISR$} Sometimes people confuse preemtion with event driven programming, by thinking events are the same as interrupts and interrupts always mean the same as preemption. This is not the case. In fact as table~\ref{pree_ev} will show you, you can use event driven programming teqnique in a non preemptive kernel, and you can have pollong driven programming while still benefitting from pre-emption. 


\begin{table}[!hbp]
$$%
\begin{tabular}{|r|rl|}
\hline
instrument & name &apa \\ \hline
drums: &"Philly" Joe & Jones\\
trumpet:& Dizzie & Gillespie\\
piano: &Art&Tatum\\ \hline
\end{tabular}
$$%
\caption{Bleh.\label{pree_ev}}
\end{table}



Most programming techiues work either you use preeption or not and that you don't need to have peemtion just to detect event's. Polling used the right way is in many situations both better safer and more predictable. You can also still make use of interrupts even in non-preeptive mode. In that case the thread affected by the even in questin will not start executing until the ISR is exited and somewhere else in the normal program an entry/exit poit is reached.

The difference is not in the programming techiques, and programs could in fact look exactly the same for the two cases. The difference is in the temporal behavious of the system. 

Consider the two programs in table~\ref{isr} and table~\ref{poll}. They each represent event  two different ways of interacting with the outside world.

\begin{table}[!hbp]
\begin{verbatim}
unsigned long cbuff[4];
void ASC0_viRx(void) interrupt ASC0_RINT
{
   cbuff[0] = ASC0_uwGetData();
   q_send(tk_sys_queues[Q_SERIAL_0_I],cbuff);
}

unsigned int thread2(void *inpar){
   unsigned long msg_buf[4];
   int depth = 0;

   printf("Thread 2 started with prio 5\n");
   while (1){
      q_receive(tk_sys_queues[Q_SERIAL_0_I],WAIT,0,msg_buf);
      depth++;
      printf("Thread2 (%d) received fron stdin: %c\n",depth,msg_buf[0]);
   }
}

unsigned int cpu_hog(void *inpar){
   int depth = 0;
   int k,l,x,y,z;

   printf("CPU \"hogg\ started with prio 7\n");
   while (1){
      for (k=0;k<10;k++)
         for (x=0;x<1000;x++)
            for (y=0;y<1000;y++)
               for (z=0;z<1000;z++)
                  l = (((x+y+1)*k)/z) % 10;
    depth++;
    printf("Hogg completed round: (%d): %d \n",depth,l);
   }
}

void root(void){
   clock_t latency = 0;

   printf("Hello world o f  TinKer targets\n");
   tk_create_thread("T2",    5,thread2,1,0x600);
   tk_create_thread("HOGG",7,cpu_hog,1,0x600);

   printf("Root started\n");
   while (TRUE) {
      latency = tk_msleep(10000);
      printf("Root \"bling\"!\n");
   }

   tk_exit(0);
}
\end{verbatim}
\caption{Events determined by interrupts.\label{isr}}
\end{table}

\begin{table}[!hbp]
\begin{verbatim}
#define PERIODT 100
unsigned long cbuff[4];
void ASC0_pollthread(void)
{
  clock_t latency;
  
   while (TRUE) {
      latency = usleep(PERIODT-latency); 
      if ( ASC0_uwHasNewData() ) {
         cbuff[0] = ASC0_uwGetData();
         q_send(tk_sys_queues[Q_SERIAL_0_I],cbuff);
      }
   }
}

unsigned int thread2(void *inpar){
   unsigned long msg_buf[4];
   int depth = 0;

   printf("Thread 2 started with prio 5\n");
   while (1){
      q_receive(tk_sys_queues[Q_SERIAL_0_I],WAIT,0,msg_buf);
      depth++;
      printf("Thread2 (%d) received fron stdin: %c\n",depth,msg_buf[0]);
   }
}

unsigned int cpu_hog(void *inpar){
   int depth = 0;
   int k,l,x,y,z;

   printf("CPU \"hogg\ started with prio 7\n");
   while (1){
      for (k=0;k<10;k++)
         for (x=0;x<1000;x++)
            for (y=0;y<1000;y++)
               for (z=0;z<1000;z++)
                  l = (((x+y+1)*k)/z) % 10;
    depth++;
    printf("Hogg completed round: (%d): %d \n",depth,l);
   }
}

void root(void){
   clock_t latency = 0;

   printf("Hello world o f  TinKer targets\n");
   tk_create_thread("T2",    5,thread2,1,0x600);
   tk_create_thread("HOGG",7,cpu_hog,1,0x600);

   printf("Root started\n");
   while (TRUE) {
      latency = tk_msleep(10000);
      printf("Root \"bling\"!\n");
   }

   tk_exit(0);
}
\end{verbatim}
\caption{Events determined by polling.\label{poll}}
\end{table}

