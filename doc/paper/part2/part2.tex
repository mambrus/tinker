\part{Design filosofies \& considerations}
\chapter{Introduction}
This part will elaborate the design filosofies that is constituted the foundation for TinKer.

One could see these a requirements specification, but I'd ratedr not. Requirement's in a development project is not scientific ber definition, because to be able to set a certain requirement up you really must have a certain idea if it's doable or not, how costly it would be to implement and at least a very general idea of how to do it.

These point's are one step ahead of this. Instead of putting up some inflexible requirements, I put up certain ambitions that I believe are of some certain value to the project. Most of them are not easilly verifiable, but still certanly have a deep impact to the end result.
\\\\
It's a matter of prioritizing and to figure out what you think is really inportant\ldots

\chapter{Readable \& Maintainable}
The idea was from the beginning to write a kernel in togeather with a thesis. I allready knew it could write a kernel and also in principle how. Readable and maintainable are closely related terms. 

The idea to back it with a text was tho aid me in seeing the difficulties from the readers perspective. Kernel design is a difficult area to teach. The problem is almost always to "communicate" the ideas and not the techniques themselfes\footnote{Bacause kernels do some "dirty" tricks that cant be described in normal programmatical terms}. 

Once you get over a certain theshold, you'll consider this easy as pie. Problem is to get over that threshold\ldots
\\\\
When one desides upon a requirement like \textit{"readability"} one really doesn't know what one's commiting for. How can you make something readable that can't be red from top to botton? And how do you \textit{meassure} this readability?
\\\\
Readablility is making everything as clear as possible and not to introduce complicating factors if they can be avoided. Sometimes this aspects goes beyond just choosing between two seemengly equal ways and in some cases a choice has to be made between readability and some other technical aspect\footnote{Performance is something often in clash with readability}. In all cases I've choosen readability because of the main reason of doing this work at all, and for the convince that hardawe will catch up much faster than kernels elvolve or new kernels come out 

Readability also has several other very nice secondary effect\footnote{But still very very important} in that TinKer is very easy to port, and hopefully many people will help in doing so.

Porting is an aspect of maintainability. In general you can say that the cleared a code gets, the more maintainable does it also become\footnote{up to a certain level}. However, maintainability is also dictated by the broader technology choices you make. In TinKers case the idea of having a software based schedule is one example. Common to these desitions are that they are so deeply enbedded in your design that they are practiacally ireversable. They do however define some sort of limit about how maintainable a project can become.

Sometimes mainainability can't only be measured in time spent to do for example a certain bug fixes or any other kind of maintanance.

For example, we'we decided that TinKer shold also be tool-transparent. This requirement drains a lot of time and work because of the time it takes to verify and test all targets based on these different tools. It's painfull process and it would be much easier to support only for example the GNU tool-chain\ldots

On the other hand, there is a certain value in that TinKer can do this at all. Moste kernels can't and the inderect result of that is the gap between embedded developpers for small targets\footnote{Devices, 1 CPU based} and traditional embedded developpers\footnote{Big system, but still embedded. Traffic control e.t.a.}.

To make a project like this readable and maintainable is not an easy task. You cant address this issue like a normal requrement, like when your requirement is broken you just file a bugrapport and "fix it". The issue is seldom isolated, and I had to re-write certaim parts of TinKer many times, not becaus it wasn't working but because I wan't happy with the readability.

Basically this is how it's been done, a slow and evoloing\footnote{I.e. you don't know exactlly how do do it. Instead you permute different solutions until you find one that's satisfying} process, involing occational re-writes and even re-designs.

\chapter{Standardized API}
One of the most important ambitions in TinKer was to base it's API on well established standards.

The reasons for this are many, but I'll mention a few
\begin{itemize}
	\item Much easier to start using
	\item Thought trough by experts 
	\item Litterature is full of books, which saves saves me the a lot of work
	\item Non standard kernels are evol	
\end{itemize}
Tinker follows POSIX standards 1003.1c\footnote{pthreads} and 1003.1b{Only part of. I.e. rt queues and semaphores.}. The ambition is to follow \textit{parts}\footnote{Since TinKer is adressing the small embedded system, we can't cover too much. The important thing is to cover the right parts.} of these standards and not to add any propriority API.

This is important, because it means that $^{a)}$ TinKer will be possible to implemet for small to very small targets and still have the important API, and $^{a)}$ you as a developper can transfer your projects as to a bigger and more powerful target as you're needs grow.

The freedom of beeing able for the user to chose a kernel for the right reasons are very near and dear to me. I want users to keep using TinKer because it's good, not because it's a ireversable choice.

\section{POSIX 1003.1c}
POSIX 1003.1c or pThreads is a fairly recent addition to the full\footnote{POSIX is \textit{HUGE}. It covers all from file-systems to shell and terminal behaviour} set of POSIX standards. describe threads in a UN*X operating system. This is a bit awkvard, because tinker is not UN*X and certanly not an full operating system.

However, it's a very good standard, and besides of the above unfortunate and a little bit missleading terminologies, it can be very well adapted and suited for a small embedded system.

TinKer implements almost all of POSIX 1003.1c and the ambition is to cover it fully.

When it comes to similarities \& differences between this standard and TinKer one has to bare a few things in mind:
\begin{itemize}
	\item TinKer is \textit{not} an OS, it's a \textit{kernel}. Many vendors targetting the embedded market call their prodicts \textit{"OS"} wich is really not accurate.
	\item There exists no processes in TinKer and the minor parts concerning threads between different processes communicating is not applicable for TinKer.
	\item POSIX 1003.1c is a standard describing an API for concurrancy, it does not mention real-time. TinKer is a real-time kernel based on this API. I.e. depending on the real-tme requirements, you might be limited in your choices of alternaltive kernels/OS:es from a portability aspect\footnote{The alternative for the end user would be to use a proprietory API wich would be even more limiting}. I.e. you have to find another \textit{real-time} kernel following the same standard\footnote{I.e. there exists kernels/systems that follow POSIX 1003.1c, but that are not real-time\ldots} 
\end{itemize}
\section{POSIX 1003.1b}
TinKer implements parts of POSIX 1003.1b, namely queues and semaphores\footnote{\textit{mqueue} and \textit{sem}}.

This standard is older than POSIX 1003.1c, which is quite funny actually. In my point of view it's a good example of the gap between the \textit{"deeply embedded school"} and the \textit{"old embedded school"}, since this standard among other thing mentions real-time, yet not realizing what real-time abilities depend upon.

So, since it's an older standard one would have to assume that there must have existed some implementation for it somewhere. It would be interesting to see how "real-timeish" this implementation would be.

Some traces can also be found in the API itself\footnote{This is not the case for the API in POSIX 1003.1c, which is a much more modern API}, since it suggests there should be a filesystem somewhere, which is just another unfortunate missconception from the UN*X community. There certanly does not have to exist any filesystem to handle for example queues. However, the standard demands it, so TinKer simulates it's existence.
\\\\
There was no reason to follow the same order of events as the historical order. TinKer inplemented pThreads first, and then based the POSIX 1003.1b queues and semaphores on top of that.

The reasons were as follows:
\begin{itemize}
	\item Queues and semaphores are just aspects of the same thing, syncronization
	\item A system needs only one syncronisation primitive, on which all other can be based on.
	\item pThreads has such a primitive, very awkward to use though.
	\item Some systems I want to use as reference, support pThreads but not POSIX 1003.1b. For these I can use this package as an isolated part.\footnote{For example, if you want to try the examples on a Cygwin Win32 target, you would need TinKers queues and semaphores. Cygwin is a fine piece of code and I use it myself very often, but it still lacks some parts\ldots}
\end{itemize}


\chapter{Small systems without compromize}
As I mentioned there exists a gap between small systems embedded designers and old school embedded designers.

These two sides have been appart for decades and not being able to come closer each othe very much probably because they don't speak the same language\footnote{in technical terms} or because of their backgrounds and traditions are different. Developpers targeting small embedded control systems very often have a electronics background thats \textit{"evolved"} into computer science, and they usually have certain difficulties seeing the \textit{"major"} benefits of programmatic methodology, varios kernals, standards and what-not's.

On the other hand, these guys have a common sence when it comes to what a endproduct is and what cosumers believe it's worth paying for.

My ambition is to help these two worlds come closer to each other, by providing a good kernel to the small embedded community\footnote{note: Only the targets are small - the community itself is huge!}, but one that enables programmatic terms that is accepted in the more advances computer science community.

Like in for most of the points in this section, the solution to this issue has the sampe properties in terms of evolution, and re-write. However, one aspect make it a little bit to handle, and that is to make ones mind up about what \textit{not} to adress:
\begin{itemize}
	\item No filesystems or file based device driver concept
	\item No processes $\Rightarrow$ i.e. no memory protection/handling
	\item End-target support only in terms of over-all architectural ports
	\item Not re-enventing standard library more than necessary
\end{itemize}
I.e. I have a certain type of system in mind to begin with, then I'll implement what's needed for that system and not more.
\\\\
To give you an idea of what that system could be like:
\begin{itemize}
	\item A CPU/MPU with 64k\footnote{CISC CPU} to 128k\footnote{RISC CPU} ROM/Flash
	\item RAM consumption \textit{staring} at 8k-16k
	\item An automotive subsystem like an engine control
	\item High processing power
	\item High volume product with few parts
\end{itemize}
As a rule of thumb, RAM is more important tham ROM/Flash. A kernel is a major memory hog when it comes to RAM. In TinKers case, RAM limits the number of either threads, queues or other kernel resources. TinKer does all resource allocation during startup, but detection is  still in run time. Besides, it will not cover the case if you need to further allocate resources in your application, wher you could still get a resource starvation problem that you have to validate on a running system. I.e. if you have an chance to design using more RAM, please do. RAM is cheap and having to much is just not possible by definition ;)
\\\\
ROM limitations are more distinct and deductable in this sentence. If your binary fits when you load it, it will run.


\chapter{CPU archetecture transpareny}
\textit{The holy grale \footnote{How does one make a kernel CPU archecture transparent? Answer: you can't. But you came more or less close\ldots}\ldots}\
\\\\
One original idea was to see how CPU transparent we could make TinKer. This is not an extemly important issue, because all it means is how long time it will take to make a port. It says nothing about either the kernals technical charecteristics nor the ports.

However, it plays a indirect role. If we could make the kernel CPU transparent, there would also be a much greater chance that TinKer got with sperad. Thereby creating a bigger communioty, who in turn would aid in indirect testing and debugging.

To deside to make a kernal transparent as a requirement is just rediculas. One simplt doesnt know how much this \textit{"beast"} can be abstracted before one tries. However, havingthis in mind from the start, letting you influence every desition makeing you do, will lead to something that's much more transparent thant not considering it at all.

Again, this was a slow maturing process, but the end result is pretty promising. 

TinKer has all archetecture specific code in inline assembly macros. These assembly lines are extremly hard to write, since thys cove not only archetectuaral difference but also tool-chain differences. However, number of lines has dropped from an average of 300 linnes to just a very few\footnote{Latest experimental code contains only 2 lines of architecture specific code!}. Having only a few architecture dependant lines of code opens up the ablility to provide many more ports.

In reality TinKer will easilly let itself be ported to all embedded targets that the GNU-newlib library has been ported for, which are quite a few.

\chapter{Tool-chain transparency}
First of, what does this mean?
\\\\
This is a terminology that I'll use in this text to cover a certain aspects that a tool-chain might inflict on a kernel. Most of the kernel is vritten in C language, and one would think that since C is standardized in itself, this would be enough, This is not the case however\ldots

\paragraph{Context switching} involves the operaton where one has to undrerstand exactly how a function call is performed, so that when the CPU returns from a certain contex switching function, it will infact return using another threads context.

Differnent compilers execute a call differently and there are no strict overall rules for this. There exists standards\footnote{Called ABI = Application Binary Interface}, but verly commonly these are repected by only one vendor.

If this venor is a dominating party, thus would be OK and we would only have to do one special adaption. But since TinKer adresses an area where there still are no dominating vendor, he have to cope with the fact that there might exist many.

Context switching can be done in many ways, but it's actually not the context switch itself thats the issue. The problem is in creating thre thread, since we then need to mimic how a function-call will look on the stack, so that when the dispatcher is finally doing context switching, that it's operations fit's with the preparation of the newly borned stack.

This particular area has been one of the toughest come up with a good solution for, but I think we now have a fairly good solution.

\paragraph{Header files \& structure} are usually considered part of a standatrd library. In fact, the which standard library you use could be viewed as part of the tool-chain\footnote{In this context, the tool-chain means C compiler, assembler and linker}. In this text I've choosen to separate them appart because a compiler can theoretically work with different standard libraries\footnote{For the GNU tool-chainwe use eithe Glibc or Newlib, depending on if it's a dedicated embedded target or not (newlib)}.

How various tool-chain separate themselfs from their respecive standard library differs greatly. In some case a clear separation can't be determined\footnote{Keil} and the two are heavilly intertwined, in some cases there exist a fair separation\footnote{GNU} and in some cases the separation is total\footnote{CADUL among others}.

Usually a compiler can't get comletly free from a C library. For example, GNU needs at least a few modules to help it start up the code. It also uses a few macros to handle endianess and floating point operations are. Furthermore, the GNU tool-chain will copy all the header files from it's correspronding library to a certain place ment to be accessible by the tools.

Very often these default headerfiles clash with TinKers, and we need to use our own. This is handled by a set of nifty macros. However, to work it requires fron the user that the serch-patch for system headerfiles come AFTER the search path for TinKer's corresponding files. 

This applies for both application and for building the kernel itself. Failing to do this will in best case be detected in compile time. So far I've never seen a case where an application has managed to build if this is not satisfied, but the compilation errors are really nasty and hard to make sence from.

I.e. Wen you build eithe application or kernel, make sure you have TinKers hearedfiles comming first in the search-path.

\paragraph{Assembly language}
Assembly language is a particulary difficult area, since it for natural resons can't be standardized as much as a high abstaction language like C.

\begin{itemize}
	\item Differnent CPU's use different instructions. The dissimilarities are big.
	\item Assembler notation can differ. For example GNU tool-chain commonly use the AT\&T notation. A very powerfull assembly notation, but a bit awkward to use.
	\item TinKer has grouped all it's architecure dependandt code in inline assembly \textit{macros}. Notation for inline assembly differ between C-compilers.
\end{itemize}
This issue is very hard to adress simply by writing the code in one way or the other. The only reasonable way to adress it in my opinion, it is to keep the number of lines as low as possible. I.e. make use of the C-compiler as much as possible.

This has led to certain compromizes in the kernal, where compile-time set-up has been replaced by run-time set-up. Some few $uS$ are lost, but the trade-off is fair.


\chapter{Standard library transparency}
This is an area of great importancem yet subtiule to identify as an issue at all.

When I first started out writing TinKer I thought I could get away without any standard library usage at all. In the \textit{"deeply embedded school"} there is a certain dislike against the usage of a standard library, more or less justified.

The reason why, is that it is believed that one looses control over the execution by not knowing what happens. Furthermore, there are certain issues concerning concurrency that are absolutly justifiable reasons \textit{not} to use a standart library\footnote{Or at least, not just any}.

The issue is tightly connected to the fact the traditional most embedded tool vendors didn't offer seperable libraries and that the ones they did offer had certain flaws that would occationaly turn up as non-acceptable system behaviour.

The above issues are actually absolutly justifiable reasons, and to my knowledge only one other kernel\footnote{RTEMS} adress this "by the book". The correct way to handle it, is to rewrite a standard library so that it satisfies all those time, behaviour and concurrency issues that you might have. A doungting task indeed\ldots

The issue with stdlib can be viewed from two angles
\begin{itemize}
	\item The TinKer kernel
	\item Your application
\end{itemize}
I've addressed the first point by letting the kernel have only two function calls it depends upon: \textit{clock()} and \textit{malloc()}. Both which can be handled even without the aid of a stdlibc however.

The second angle is different. Except the API covered by POSIX 1003.1c and 1003.1b, the kernel doesn't aid the application in any way. I.e. you have to make sure youself if a certain function is safe to use in a concurrent environment or not. You can make it safe, it's not very hard. But the project domain has to be limited somewhere, and even if each API is realtivly easy to certify, there are number of functions are just to be to adress. Especially if you recall that we want to be as independant as possible, i.e. by being able to colaberate with more stdlib than one\ldots
The things to adress when protecting your application
\begin{itemize}
	\item Reentrancy and thread safety\footnote{Fubctions in this cathegory are all that uses file-handles. Most notably: printf, scanf\ldots}. If a function has \textit{"states"} or some other \textit{"side effect"}, wrap a mutex around it. Best thing to do is banning the usage of the function, and make the wrap in another following a certain naming convention thats easy for the programmer to rember. Optionally you can even wrap this new function around nifty macros, making appear as if it were the original function call\footnote{This is how TinKer does it}
	\item Dynamic memory allocation\footnote{,alloc, malloc \'et all}. In an small embedded system you should carefully evaluate if you need dynamic memory allocation at all. You probably have limited resources, and even if concurrency is not the problem, starvation might be\footnote{And this is certanly not nice to find out during run-time}. Many alloc implementations also have an undeterministic execution time depending on if the available memory on the heap is fragmented or not. Dynamic memory allocation has states and is inheritly \textit{not thread safe}. For the GNU tool-chain this possible to handle because of the system function call-outs, and TinKer might adress this issue differently in the future.
\end{itemize}
By originally having the ambition to not use any library at all, TinKer evolved to have very few dependancies towards one. Actually, TinKer is absolutly dependant of only one standard library function call to be able to dispatch a schedule\footnote{The primary purpose of any kernel}: \textit{clock()}. And even this is wrapped around a macro, so it can be temporarily delt with\footnote{at least temporary when when you write a new port. A complete port must have this implemented}. However, no port is particullary usefull without beeing able to schedule real threads. So to complete a port, implementing following API will make life much easier to the programmer.
\begin{itemize}
	\item clock
	\item malloc
	\item printf
\end{itemize}
What about memory allocation then? You said this bas \textit{"a bad thing"}? It is, but only if used in a concurrent situation. TinKer needs memory for various of purposes, and using malloc\footnote{malloc and friends} is a conveniant way to get it. However, we dont have to malloc and free all the time if we pre-allocate during startup. Instead we use memory pools that store various kernel elements until thys're needed. You only have to thet the kernel know, and it will preallocate those during startup. 

This solves both the concurrency issue and the timelyness issue whit the small price of perhaps using slightly more RAM that the system otherwize could get away with.  However it doesnt so√∂ve the applications needs. One way to solve this could be to extend the internal service to cover the application also. So far I've been a little reluctant to do so however\ldots

So to make wrap this discussion up a bit, issues with standard library can be delt in several ways and by several instances. We concluded that whence you've built the kernel, it doen't need any libc and that you application can hadle the remaining issues as follows:

\begin{itemize}
	\item Thread safeting, using function wrappers and optinally additional macro wrappers
	\item Protection on system call-outs (GNU/Newlib only)
	\item Don't use stdlibc.
\end{itemize}




\chapter{Real real-time}

\section{Preemtion by need-only basis}
\section{TinKers dual time concepts}

\chapter{Runnable in desktop as mini-kernels}
aiding of debugging and development

\chapter{Well defined limitations}
no filesys, no OS

\chapter{GNU and other thoughts}